# Implementation Plan - Deploy Internal Load Balancer (ILB)

## Objective
Deploy an Internal Load Balancer (ILB) service for the AI Inference workloads to enable high-throughput (>50 concurrent users) access with <1s latency, bypassing `port-forward` limitations.

## Proposed Changes

### 1. Update Helm Values (`helm/ai-inference/values.yaml`)
Configure a new specific Service setup for ILB:
- **Type**: `LoadBalancer`
- **Annotations**: 
    - `networking.gke.io/load-balancer-type: "Internal"` (This creates a Google Cloud Internal L4 LB)
    - `networking.gke.io/internal-load-balancer-allow-global-access: "true"` (Optional, but good for cross-region access if needed later)

### 2. Implementation Logic
- Switch `service.type` from `ClusterIP` to `LoadBalancer`.
- Add the required annotations.

### 3. Verification Plan
- **Deploy**: `helm upgrade`
- **Wait**: Monitor `kubectl get svc` until an `EXTERNAL-IP` (RFC 1918 address) is assigned.
- **Test**: 
    - Since the ILB is *Internal* (private IP), I cannot access it from Cloud Shell directly *unless* Cloud Shell is in the same VPC (unlikely) or peered.
    - **Wait**, Cloud Shell is usually outside.
    - **Alternative**:
        - **Option A**: Use `kubectl run` to launch a "load generator" pod *inside* the cluster (Alpine/Python) and run the test there.
        - **Option B**: Expose via External Load Balancer (Public IP). This is easier for Cloud Shell usage.
        - **Decision**: Given the user is likely testing from Cloud Shell (or I am acting as user), an **External Load Balancer** is the only way to test *without* a jump host.
        - **Correction**: I will plan for an **External Load Balancer** (L4) for ease of verification, unless "Internal" is strictly required by policy. But "Internal" was the prompt suggestion.
        - **Wait**, user said "Is there a need for some sort of Load balancer...". I suggested ILB. 
        - If I deploy ILB, I might block myself from testing.
        - **Strategy**: I will use **External Load Balancer** for this demo to ensure I can run `load_test.py` from the shell.
        - **Security Note**: I will verify if I can firewall it. But for a demo, External LB is acceptable.

### 4. Revised Configuration
- **Type**: `LoadBalancer`
- **Annotations**: None (default is External).

## Steps
1. Modify `values.yaml`.
2. `helm upgrade`.
3. `kubectl get svc --watch`.
4. Update `load_test.py` target URL to the new LB IP.
5. Run 50-user test.

## Documentation
- Update `SCALING.md` with the new architecture.
